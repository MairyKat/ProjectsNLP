# -*- coding: utf-8 -*-
"""Text Classification

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yzdkQuxHDZtr6E0-MHroIlZ3H1lREQY8
"""

#Hay que construir 1 notebook que resuelva una tarea de procesamiento de texto, comparando alguna de las técnicas presentadas en las actividades de exploración de esta semana, con alguna de las técnicas utilizadas a lo largo del curso.
#Hay que explicar los detalles de cada uno de los pasos que se realicen y explicar y discutir los resultados obtenidos.
#También incluir todas las referencias utilizadas.

#HE ELEGIDO CREAR UN MODELO DE RNN Y UN MODELO DE CNN YA QUE LOS DOS SON CAPACES DE TRABAJAR CON DATOS SECUANCIALES

#SE CARGA UN DATASET DE TEXTO Y  CLASIFICACIÓN BINARIA

import pandas as pd
from google.colab import drive
import matplotlib.pyplot as plt


drive.mount('/content/drive')
path = "/content/drive/MyDrive/Colab Notebooks/"

ebt= path + "emails.csv"

df= pd.read_csv(ebt)
df
#El dataset contiene dos columnas:
#Una llamada 'text' que contiene el texto de un correo.
#Y otra llamada 'spam', que indica si ese correo se ha considerado spam.

#SE IMPORTAN LAS LIBRERIAS NECESARIAS
import keras
keras.__version__

from keras.layers import SimpleRNN
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from tensorflow.keras import preprocessing
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Conv1D, GlobalMaxPooling1D, Flatten
from keras.models import Sequential
from keras import layers
from keras.callbacks import EarlyStopping
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import nltk
import random
import re
import tensorflow as tf
import numpy as np
import os

#SE SETEAN LOS PRAMETROS
max_features = 10000 # Número máximo de palabras a considerar como características
maxlen = 500 # Longitud máxima de las secuencias de texto
batch_size = 32 # Tamaño del lote (batch) para el entrenamiento
embedding_dim = 50  # Dimensión de la capa de embedding
filters = 250  # Número de filtros convolucionales
kernel_size = 3  # Tamaño del kernel en la capa convolucional
epochs = 25 # Número de épocas de entrenamiento
lstm_units = 100  # Número de unidades en la capa LSTM

#SE LIMPIA EL TEXTO Y SE PREPARAN LOS DATOS
idx = random.randint(0, len(df)-1)
before_process = df.iloc[idx][0]

#Se usa una funcion de expresiones regulares
def process(x):
    x = re.sub('[,\.!?:()"]', '', x)
    x = re.sub('<.*?>', ' ', x)
    x = re.sub('http\S+', ' ', x)
    x = re.sub('[^a-zA-Z0-9]', ' ', x)
    x = re.sub('\s+', ' ', x)
    return x.lower().strip()

print("----Antes de limpiar caracteres no deseados:")
print(df.text[4])
#SE APLICA LA FUNCION 'process' PARA LIMPIAR CARACTERES NO DESEADOS
df['text'] = df['text'].apply(lambda x: process(x))
after_process = df.iloc[idx][0]
print("----Despues de limpiar caracteres no deseados:")
print(df.text[4])

#Se borran los STOPWORDS
nltk.download('stopwords')
wpt = nltk.WordPunctTokenizer()

sw_set = set(nltk.corpus.stopwords.words('english'))
sw_set.add('subject') #para eliminar la palabra 'subject' que hay al principio

def sw_remove(x):
    words = wpt.tokenize(x)
    filtered_list = [word for word in words if word not in sw_set]
    return ' '.join(filtered_list)

print("----Antes de limpiar palabras no deseadas:")
print(df.text[4])
df['text'] = df['text'].apply(lambda x: sw_remove(x))
after_removal = sw_remove(after_process)
print("----Despues de limpiar palabras no deseadas:")
print(df.text[4])

#SE HACE EL SPLIT DE LOS DATOS QUEDANDONOS CON 20% PARA TEST y 80% PARA TRAIN

train_text, test_text, train_spam, test_spam = train_test_split(df['text'], df['spam'], test_size=0.2, stratify=y, random_state=123)

print('\033[1m' + 'train_text:' + '\033[0m', train_text.shape)
print('\033[1m' + 'test_text:' + '\033[0m', test_text.shape)
print('\033[1m' + 'train_spam:' + '\033[0m', train_spam.shape)
print('\033[1m' + 'test_spam:' + '\033[0m', test_spam.shape)

#SE TOKENIZA EL TEXTO
#SE GENERA UN INDICE DE TODAS LAS PALABRAS QUE HAY EN EL SET DE TRAIN
tokenizer = Tokenizer(num_words=max_features)
tokenizer.fit_on_texts(train_text)
#No estoy haciendo fit el test para no darle ventaja a modelo
word_index = tokenizer.word_index
vocab_size = len(tokenizer.word_index) + 1

train_sequences = tokenizer.texts_to_sequences(train_text)
test_sequences = tokenizer.texts_to_sequences(test_text)

#CARGAR VECTORES PRENTRENADOS

glove_dir = '/content/drive/MyDrive/Colab Notebooks/'

#Diccionario de embeddings
embeddings_index = {}
f = open(os.path.join(glove_dir, 'glove.txt'))
for line in f:
    values = line.split()
    word = values[0]
    coefs = np.asarray(values[1:], dtype='float32')
    embeddings_index[word] = coefs
f.close()

print('Found %s word vectors.' % len(embeddings_index))

#Matriz de embeding para el modelo
embedding_matrix = np.zeros((max_features, embedding_dim))
for word, i in word_index.items():
    embedding_vector = embeddings_index.get(word)
    if i < max_features:
        if embedding_vector is not None:
            embedding_matrix[i] = embedding_vector

#AJUSTAR LA LONGITUD DE LAS SECUENCIAS
print('Pad sequences (samples x time)')
input_train_text = preprocessing.sequence.pad_sequences(train_sequences, maxlen=maxlen)
input_test_text = preprocessing.sequence.pad_sequences(test_sequences, maxlen=maxlen)
print('input_train shape:', input_train_text.shape)
print('input_test shape:', input_test_text.shape)

#SE CREA UN MODELO DE RED NEURONAL RECURRENTE DE EMBEDDINGS PREENTRENADOS SIN CONGELAR
modelRNN = Sequential()
modelRNN.add(Embedding(max_features, embedding_dim, input_length=maxlen))
modelRNN.add(Flatten())
modelRNN.add(Dense(50, activation="relu"))
modelRNN.add(Dense(50, activation='relu'))
modelRNN.add(Dense(1, activation='sigmoid'))
modelRNN.summary()

modelRNN.layers[0].set_weights([embedding_matrix])
modelRNN.layers[0].trainable = True

#Early_stopping                                                                                                               cuando val_loss empeore
#Permitimos hasta 3 epocas sin mejora
#Restauramos pesos a los mejores obtenidos una vez pare
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

#COMPILAMOS EL MODELO
modelRNN.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['acc'])
# Hacemos el fit
history = modelRNN.fit(input_train_text, train_spam,
                    epochs=epochs,
                    batch_size=batch_size,
                    validation_data=(input_test_text, test_spam),
                    callbacks=[early_stopping])

#SE VISUALIZAN LOS GRAFICOS DE LOS RESULTADOS

acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(len(acc))

plt.plot(epochs_range, acc, 'bo', label='Training acc')
plt.plot(epochs_range, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()

plt.figure()

plt.plot(epochs_range, loss, 'bo', label='Training loss')
plt.plot(epochs_range, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

# SE EVALUA EL MODELO
scoreRNN = modelRNN.evaluate(input_test_text, test_spam, verbose=1)
print("Accuracy: ", scoreRNN[1])

#SE HACE LA PREDICCIÓN DEL MODELO
predRNN = (modelRNN.predict(input_test_text)>0.5).astype("int32")
confusion_matrix(test_spam, predRNN)

#SE PINTAN LOS 10 PRIMEROS VALORES DE LOS RESULTADOS DE PREDICCION PARA VER LA FORMA BINARIA QUE DEBE TENER
for i in range(10):
    print(predRNN[i])

#SE CREA LA MATRIX DEL MODELO

def plot_confusion_matrix(y, y_preds):

    plt.figure(figsize=(8, 6))
    sns.heatmap(pd.DataFrame(confusion_matrix(y, y_preds)), annot=True, fmt='d', cmap='YlGnBu', alpha=0.8, vmin=0)

#MATRIX DEL PRIMER MODELO

plot_confusion_matrix(test_spam, predRNN)
print(classification_report(test_spam, predRNN))

#El modelo parece que funciona bastente bien
#ya que ha dado solamente 10 y 14 falsos positivos. Es decir ha detectado como 1 (spam) mensajes que no lo eran (0) y al revés.

# SE CONSTRUYE UN MODELO DE RED NEURONAL CONVOLUCIONAL
#Fuente: https://medium.com/saarthi-ai/sentence-classification-using-convolutional-neural-networks-ddad72c7048c

modelCNN = Sequential()
modelCNN.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))
modelCNN.add(layers.Conv1D(128, 5, activation='relu'))
modelCNN.add(layers.GlobalMaxPooling1D())
modelCNN.add(layers.Dense(10, activation='relu'))
modelCNN.add(layers.Dense(1, activation='sigmoid'))
modelCNN.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

#Creamos el early_stopping para que
#pare cuando cuando val_loss empeore
#permitimos hasta 3 epocas sin mejora
#restauramos pesos a los mejores obtenidos una vez pare
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
# Compilamos el modelo
modelCNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])
# Hacemos el fit
history = modelCNN.fit(input_train_text, train_spam, batch_size=batch_size, epochs=epochs, validation_data=(input_test_text, test_spam), callbacks=[early_stopping])

#SE VISUALIZAN LOS GRAFICOS DE LOS RESULTADOS
acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(len(acc))

plt.plot(epochs_range, acc, 'bo', label='Training acc')
plt.plot(epochs_range, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()

plt.figure()

plt.plot(epochs_range, loss, 'bo', label='Training loss')
plt.plot(epochs_range, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

# SE EVALUA EL MODELO CALCULANDO LA ACCURACY
scoreCNN= modelCNN.evaluate(input_test_text, test_spam, batch_size=batch_size)
print(f'Test accuracy:',scoreCNN[1])

#SE HACE LA PREDICCIÓN DEL MODELO

predCNN = (modelCNN.predict(input_test_text)>0.5).astype("int32")

confusion_matrix(test_spam, predCNN)

#SE CREA LA MATRIX DEL MODELO
plot_confusion_matrix(test_spam, predCNN)
print(classification_report(test_spam, predCNN))

#El modelo parece que funciona muy bien
#Solamente ha dado 3 y 6 falsos positivos/negativo. Es decir ha detectado como 1 (spam) mensajes que no lo eran (0) y al revés